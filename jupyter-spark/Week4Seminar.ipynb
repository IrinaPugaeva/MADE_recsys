{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as spf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "import lightfm\n",
    "import lightfm.data as ld\n",
    "import lightfm.evaluation as lv\n",
    "\n",
    "import tqdm\n",
    "import json\n",
    "import optuna\n",
    "\n",
    "import tensorboardX as tb\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(31337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"dnikanorova\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = spark.read.json(\"/user/dnikanorova/data/random_100k.json\")\n",
    "\n",
    "data_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    data_all\n",
    "        .filter(spf.col(\"time\") > 0.5)\n",
    "        .select(\"user\", \"track\", \"time\")\n",
    "        .toPandas()\n",
    "        .drop_duplicates(subset=[\"user\", \"track\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positives = data[data[\"time\"] > 0.8].copy()\n",
    "positives[\"test\"] = np.random.random(len(positives)) >= 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_counts = positives[~positives[\"test\"]].groupby(\"user\").size()\n",
    "users = set(user_counts[user_counts >= 5].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track_counts = positives[~positives[\"test\"]].groupby(\"track\").size()\n",
    "tracks = set(track_counts[track_counts >= 5].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = positives[~positives[\"test\"] & positives[\"user\"].isin(users) & positives[\"track\"].isin(tracks)]\n",
    "test_data = positives[positives[\"test\"] & positives[\"user\"].isin(users) & positives[\"track\"].isin(tracks)]\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = ld.Dataset()\n",
    "dataset.fit(users, tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_interactions, _ = dataset.build_interactions(train_data[[\"user\", \"track\"]].itertuples(index=False, name=None))\n",
    "test_interactions, _ = dataset.build_interactions(test_data[[\"user\", \"track\"]].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(epochs=1, at=10, loss=\"warp\", no_components=30, learning_rate=0.01, max_sampled=10, user_alpha=0.0, item_alpha=0.0, threads=30, verbose=False):\n",
    "    model = lightfm.LightFM(\n",
    "        no_components=no_components,\n",
    "        loss=loss,\n",
    "        learning_rate=learning_rate,\n",
    "        max_sampled=max_sampled,\n",
    "        user_alpha=user_alpha,\n",
    "        item_alpha=user_alpha,\n",
    "    )\n",
    "\n",
    "    precisions_at = []\n",
    "    for epoch in range(epochs):\n",
    "        model = model.fit_partial(train_interactions, num_threads=threads)\n",
    "        precision_at = lv.precision_at_k(model, test_interactions, train_interactions=train_interactions, k=at, num_threads=threads)\n",
    "        if verbose:\n",
    "            print(f\"{epoch}:\\t{np.mean(precision_at)} +/- {ss.sem(precision_at) * 1.96}\")\n",
    "        precisions_at.append(np.mean(precision_at))\n",
    "            \n",
    "    return model, precisions_at\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    loss = trial.suggest_categorical(\"loss\", [\"warp\", \"bpr\"])\n",
    "    no_components = trial.suggest_categorical(\"no_components\", [10, 30, 50])\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [0.001, 0.01])\n",
    "    max_sampled = trial.suggest_categorical(\"max_sampled\", [10, 20, 50, 100])\n",
    "    user_alpha = trial.suggest_categorical(\"user_alpha\", [0.0, 0.001, 0.01])\n",
    "    item_alpha = trial.suggest_categorical(\"item_alpha\", [0.0, 0.001, 0.01])\n",
    "    \n",
    "    model, precisions_at = fit_model(\n",
    "        epochs=1, \n",
    "        at=10,\n",
    "        loss=loss,\n",
    "        no_components=no_components, \n",
    "        learning_rate=learning_rate, \n",
    "        max_sampled=max_sampled, \n",
    "        user_alpha=user_alpha, \n",
    "        item_alpha=item_alpha,\n",
    "    )\n",
    "    \n",
    "    return precisions_at[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = {'loss': 'warp',\n",
    " 'no_components': 50,\n",
    " 'learning_rate': 0.01,\n",
    " 'max_sampled': 100,\n",
    " 'user_alpha': 0.0,\n",
    " 'item_alpha': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, precisions_at = fit_model(\n",
    "    epochs=100,\n",
    "    at=10,\n",
    "    loss=best_params[\"loss\"],\n",
    "    no_components=best_params[\"no_components\"], \n",
    "    learning_rate=best_params[\"learning_rate\"], \n",
    "    max_sampled=best_params[\"max_sampled\"],\n",
    "    user_alpha=best_params[\"user_alpha\"],\n",
    "    item_alpha=best_params[\"item_alpha\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = pl.subplots()\n",
    "\n",
    "ax.plot(np.arange(len(precisions_at)), precisions_at)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save track embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases, embeddings = model.get_item_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track_meta = pd.read_json(DATA_DIR + \"tracks.json\", lines=True)\n",
    "track_meta[\"dataset_index\"] = track_meta[\"track\"].map(lambda t: dataset.mapping()[2].get(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_tracks = track_meta[pd.notnull(track_meta[\"dataset_index\"])].sort_values(\"dataset_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tb.SummaryWriter(comment='msd_ligtfm_embeddings', log_dir=DATA_DIR + \"tb\")\n",
    "writer.add_embedding(embeddings, metadata=list(dataset_tracks[[\"artist\", \"title\"]].itertuples(index=False, name=None)), tag=\"lightfm\", metadata_header=[\"artist\", \"title\"])\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks = dataset_tracks[\"track\"].values\n",
    "users = [user for user, index in sorted(dataset.mapping()[0].items(), key=lambda kv: kv[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(1, np.arange(dataset.item_features_shape()[0]), num_threads=30)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"recommendations_SVD.json\", \"w\") as rf:\n",
    "    for user_index in tqdm.tqdm(range(dataset.user_features_shape()[0])):\n",
    "        predictions = model.predict(user_index, np.arange(dataset.item_features_shape()[0]), num_threads=30)\n",
    "        top = tracks[np.argsort(predictions)[-100:]]\n",
    "        recommendation = {\n",
    "            \"user\": int(users[user_index]),\n",
    "            \"tracks\": top.tolist()\n",
    "        }\n",
    "        rf.write(json.dumps(recommendation) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atp-mobod_2022",
   "language": "python",
   "name": "atp-mobod_2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
