{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CrjZ-Ma78a0c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_lightning\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/ed/7d91e1958f0d48b439fae0de8ece3de3ce8c3d4e03b04bd3c007ba879a49/pytorch_lightning-1.9.5-py3-none-any.whl (829kB)\n",
      "\u001b[K     |████████████████████████████████| 839kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.57.0 (from pytorch_lightning)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/02/a2cff6306177ae6bc73bc0665065de51dfb3b9db7373e122e2735faf0d97/tqdm-4.65.0-py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 16.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=4.0.0 (from pytorch_lightning)\n",
      "  Downloading https://files.pythonhosted.org/packages/31/25/5abcd82372d3d4a3932e1fa8c3dbf9efac10cc7c0d16e78467460571b404/typing_extensions-4.5.0-py3-none-any.whl\n",
      "Requirement already satisfied: packaging>=17.1 in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from pytorch_lightning) (19.2)\n",
      "Collecting torch>=1.10.0 (from pytorch_lightning)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/18/d97cdc571b4cb90c0d3613cffb19a55ef1e48e74e0c5a6c293e97234b7d3/torch-1.13.1-cp37-none-macosx_10_9_x86_64.whl (135.3MB)\n",
      "\u001b[K     |████████████████████████████████| 135.3MB 1.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/47/6e9f9b41c48750a45ad07cc6d43a2979bfc09e6989656aece97cc59cbef1/torchmetrics-0.11.4-py3-none-any.whl (519kB)\n",
      "\u001b[K     |████████████████████████████████| 522kB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lightning-utilities>=0.6.0.post0 (from pytorch_lightning)\n",
      "  Downloading https://files.pythonhosted.org/packages/5d/ec/a20c5d5f26894913da028110310ba55ee254e1b7ff0ff78441e4eeb7291f/lightning_utilities-0.8.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from pytorch_lightning) (1.21.2)\n",
      "Collecting fsspec[http]>2021.06.0 (from pytorch_lightning)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/64/f0d369ede0ca54fdd520bdee5086dbaf0af81dac53a2ce847bd1ec6e0bf1/fsspec-2023.1.0-py3-none-any.whl (143kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyYAML>=5.4 (from pytorch_lightning)\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/f6/7e91fbb58c9ee528759aea5892e062cccb426720c5830ddcce92eba00ff1/PyYAML-6.0-cp37-cp37m-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from packaging>=17.1->pytorch_lightning) (2.4.2)\n",
      "Requirement already satisfied: six in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from packaging>=17.1->pytorch_lightning) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.0.0; python_version < \"3.8\" in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from lightning-utilities>=0.6.0.post0->pytorch_lightning) (4.8.1)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\" (from fsspec[http]>2021.06.0->pytorch_lightning)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/a8/8a7e53fcf159eb838d96810de2b4d05e27b38bf9804275b13ddc952a32f9/aiohttp-3.8.4-cp37-cp37m-macosx_10_9_x86_64.whl (354kB)\n",
      "\u001b[K     |████████████████████████████████| 358kB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests; extra == \"http\" in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.26.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=4.0.0; python_version < \"3.8\"->lightning-utilities>=0.6.0.post0->pytorch_lightning) (3.5.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning)\n",
      "  Downloading https://files.pythonhosted.org/packages/99/91/3da45532025fe9860a70739f1cb5ccc1aba6a18e62dd181402174fc67b6c/frozenlist-1.3.3-cp37-cp37m-macosx_10_9_x86_64.whl\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning)\n",
      "  Using cached https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.5)\n",
      "Collecting asynctest==0.13.0; python_version < \"3.8\" (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning)\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/b6/8d17e169d577ca7678b11cd0d3ceebb0a6089a7f4a2de4b945fe4b1c86db/asynctest-0.13.0-py3-none-any.whl\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning)\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/a5/4ee9ed42f0eadf10a7eaa0d67e26107c0385e62cee49bacd2bd7ad934ae9/multidict-6.0.4-cp37-cp37m-macosx_10_9_x86_64.whl\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/15/6a532d39772d24e0383b83bccb252ddc97da7943fca96c1e1696af834e48/yarl-1.8.2-cp37-cp37m-macosx_10_9_x86_64.whl (60kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from requests; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from requests; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from requests; extra == \"http\"->fsspec[http]>2021.06.0->pytorch_lightning) (3.2)\n",
      "\u001b[31mERROR: rich 12.6.0 has requirement pygments<3.0.0,>=2.6.0, but you'll have pygments 2.4.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: flake8 5.0.4 has requirement importlib-metadata<4.3,>=1.1.0; python_version < \"3.8\", but you'll have importlib-metadata 4.8.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: connexion 2.14.1 has requirement packaging>=20, but you'll have packaging 19.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apache-airflow 2.5.0 has requirement flask<2.3,>=2.2, but you'll have flask 2.0.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tqdm, typing-extensions, torch, torchmetrics, lightning-utilities, frozenlist, aiosignal, asynctest, multidict, yarl, aiohttp, fsspec, PyYAML, pytorch-lightning\n",
      "  Found existing installation: tqdm 4.36.1\n",
      "    Uninstalling tqdm-4.36.1:\n",
      "      Successfully uninstalled tqdm-4.36.1\n",
      "  Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Found existing installation: fsspec 0.5.2\n",
      "    Uninstalling fsspec-0.5.2:\n",
      "      Successfully uninstalled fsspec-0.5.2\n",
      "  Found existing installation: PyYAML 5.1.2\n",
      "\u001b[31mERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n",
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/9f/d532d37f10ac7af136d4c2ba71e1fe7af0f3cc0cc076dfc05826171e9737/tensorboardX-2.6-py2.py3-none-any.whl (114kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 122kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf<4,>=3.8.0 (from tensorboardX)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/8f/d9db035740002d61b4140aaef53a8bac7e316b18ec8744eb6c1fcf83c310/protobuf-3.20.3-cp37-cp37m-macosx_10_9_x86_64.whl (981kB)\n",
      "\u001b[K     |████████████████████████████████| 983kB 5.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from tensorboardX) (19.2)\n",
      "Requirement already satisfied: numpy in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.21.2)\n",
      "Requirement already satisfied: six in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from packaging->tensorboardX) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages (from packaging->tensorboardX) (2.4.2)\n",
      "Installing collected packages: protobuf, tensorboardX\n",
      "Successfully installed protobuf-3.20.3 tensorboardX-2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1CmEukeg8Njd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandersidorenko/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "\n",
    "import tqdm\n",
    "import json\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "# import tensorboardX as tb\n",
    "# import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(31337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4cLf0zW8Njf"
   },
   "source": [
    "## Create pairs (first track, subsequent track, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DHUIFjU0Z09C"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MKlgAqq-8Njg"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/alexandersidorenko/ira/recsys_made/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Y9aeehkP8Njh"
   },
   "outputs": [],
   "source": [
    "data = pd.read_json(DATA_DIR + \"data_seminar_04.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>track</th>\n",
       "      <th>time</th>\n",
       "      <th>latency</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>experiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last</td>\n",
       "      <td>2022-06-13 11:39:37.645</td>\n",
       "      <td>4013</td>\n",
       "      <td>18934</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'AA': 'T1', 'COLLABORATIVE': 'T1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>next</td>\n",
       "      <td>2022-06-13 11:39:37.683</td>\n",
       "      <td>9693</td>\n",
       "      <td>29738</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>3079.0</td>\n",
       "      <td>{'AA': 'C', 'COLLABORATIVE': 'C'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>next</td>\n",
       "      <td>2022-06-13 11:39:37.692</td>\n",
       "      <td>9693</td>\n",
       "      <td>3079</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>20078.0</td>\n",
       "      <td>{'AA': 'C', 'COLLABORATIVE': 'C'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>next</td>\n",
       "      <td>2022-06-13 11:39:37.700</td>\n",
       "      <td>9693</td>\n",
       "      <td>20078</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>12044.0</td>\n",
       "      <td>{'AA': 'C', 'COLLABORATIVE': 'C'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>next</td>\n",
       "      <td>2022-06-13 11:39:37.708</td>\n",
       "      <td>9693</td>\n",
       "      <td>12044</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>37424.0</td>\n",
       "      <td>{'AA': 'C', 'COLLABORATIVE': 'C'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  message               timestamp  user  track  time   latency  \\\n",
       "0    last 2022-06-13 11:39:37.645  4013  18934  0.02  0.000206   \n",
       "1    next 2022-06-13 11:39:37.683  9693  29738  1.00  0.000902   \n",
       "2    next 2022-06-13 11:39:37.692  9693   3079  0.06  0.000923   \n",
       "3    next 2022-06-13 11:39:37.700  9693  20078  1.00  0.000858   \n",
       "4    next 2022-06-13 11:39:37.708  9693  12044  0.00  0.000927   \n",
       "\n",
       "   recommendation                          experiments  \n",
       "0             NaN  {'AA': 'T1', 'COLLABORATIVE': 'T1'}  \n",
       "1          3079.0    {'AA': 'C', 'COLLABORATIVE': 'C'}  \n",
       "2         20078.0    {'AA': 'C', 'COLLABORATIVE': 'C'}  \n",
       "3         12044.0    {'AA': 'C', 'COLLABORATIVE': 'C'}  \n",
       "4         37424.0    {'AA': 'C', 'COLLABORATIVE': 'C'}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zj9JftT88Njh"
   },
   "outputs": [],
   "source": [
    "Pair = namedtuple(\"Session\", [\"user\", \"start\", \"track\", \"time\"])\n",
    "\n",
    "def get_pairs(user_data):\n",
    "    pairs = []\n",
    "    first = None\n",
    "    for _, row in user_data.sort_values(\"timestamp\").iterrows():\n",
    "        if first is None:\n",
    "            first = row[\"track\"]\n",
    "        else:\n",
    "            pairs.append(Pair(row[\"user\"], first, row[\"track\"], row[\"time\"]))\n",
    "        \n",
    "        if row[\"message\"] == \"last\":\n",
    "            first = None\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c_Ifi9_8Nji"
   },
   "outputs": [],
   "source": [
    "pairs = pd.DataFrame(\n",
    "    data\n",
    "    .groupby(\"user\")\n",
    "    .apply(get_pairs)\n",
    "    .explode()\n",
    "    .values\n",
    "    .tolist(),\n",
    "    columns=[\"user\", \"start\", \"track\", \"time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eA0LzG3Z8Nji"
   },
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots()\n",
    "sns.histplot(pairs[\"time\"], ax=ax)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkYDflFK8Njj"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cE63YQAi8Njj"
   },
   "outputs": [],
   "source": [
    "rdm = np.random.random(len(pairs))\n",
    "train_data = pairs[rdm < 0.8]\n",
    "val_data = pairs[(rdm >= 0.8) & (rdm < 0.9)]\n",
    "test_data = pairs[rdm >= 0.9]\n",
    "\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2N72w3Ym8Njl"
   },
   "outputs": [],
   "source": [
    "class ContextualRanker(pl.LightningModule):\n",
    "    def __init__(self, embedding_dim=10):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # We won't have embeddings for everything, but that's ok\n",
    "        self.context = nn.Embedding(num_embeddings=50000, embedding_dim=self.embedding_dim)\n",
    "        self.track = nn.Embedding(num_embeddings=50000, embedding_dim=self.embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = self.context(x[:, 0]) # start track\n",
    "        track = self.track(x[:, 1]) # next track\n",
    "        return torch.sum(context * track, dim=1)\n",
    "            \n",
    "    def step(self, batch, batch_idx, metric, prog_bar=False):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        loss = F.mse_loss(predictions, y.float(), reduction='mean')\n",
    "        self.log(metric, loss, prog_bar=prog_bar)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx, prog_bar=False):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        targets = y[:, 0].float()\n",
    "        avgs = y[:, 1].float()\n",
    "        rdms = y[:, 2].float()\n",
    "\n",
    "        loss = F.mse_loss(predictions, targets, reduction='mean')\n",
    "        avg_loss = F.mse_loss(avgs, targets, reduction='mean')\n",
    "        rdm_loss = F.mse_loss(rdms, targets, reduction='mean')\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=prog_bar)\n",
    "        self.log(\"avg_loss\", avg_loss, prog_bar=prog_bar)\n",
    "        self.log(\"rdm_loss\", rdm_loss, prog_bar=prog_bar)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"train_loss\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"val_loss\", True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "        scheduler = {\n",
    "            'scheduler': lr_scheduler,\n",
    "            'reduce_on_plateau': True,\n",
    "            'monitor': 'val_loss'\n",
    "        }\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSZTEW7h9d3p"
   },
   "outputs": [],
   "source": [
    "class ContextualRankerData(pl.LightningDataModule):\n",
    "  def __init__(self, train_data, val_data, test_data, features):\n",
    "      super().__init__()\n",
    "      self.train_data = train_data\n",
    "      self.val_data = val_data\n",
    "      self.test_data = test_data\n",
    "      self.features = features\n",
    "\n",
    "  def prepare_data(self):\n",
    "      self.test_data = self.test_data.assign(rdm = np.random.random(len(self.test_data))).assign(avg = self.train_data[\"time\"].mean())\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "      if stage == \"fit\" or stage is None:\n",
    "        self.train_dataset = td.TensorDataset(\n",
    "            torch.from_numpy(self.train_data[self.features].values), \n",
    "            torch.from_numpy(self.train_data[\"time\"].values)\n",
    "            )\n",
    "\n",
    "        self.val_dataset = td.TensorDataset(\n",
    "            torch.from_numpy(self.val_data[self.features].values), \n",
    "            torch.from_numpy(self.val_data[\"time\"].values)\n",
    "            )\n",
    "        \n",
    "      if stage == \"test\" or stage is None:  \n",
    "        self.test_dataset = td.TensorDataset(\n",
    "            torch.from_numpy(self.test_data[self.features].values),\n",
    "            torch.from_numpy(self.test_data[[\"time\", \"avg\", \"rdm\"]].values)\n",
    "        )\n",
    "  def train_dataloader(self):\n",
    "      return td.DataLoader(self.train_dataset, batch_size=2048, shuffle=True, num_workers=0)\n",
    "\n",
    "  def val_dataloader(self):\n",
    "      return td.DataLoader(self.val_dataset, batch_size=2048, num_workers=0)\n",
    "\n",
    "  def test_dataloader(self):\n",
    "      return td.DataLoader(self.test_dataset, batch_size=512, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWZ8cqTZ8Njm"
   },
   "outputs": [],
   "source": [
    "net = ContextualRanker(embedding_dim=100)\n",
    "data_module = ContextualRankerData(train_data, val_data, test_data, features = [\"start\", \"track\"])\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=300,\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        checkpoint_callback\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omCmoxVhGfJ2"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/lightning_logs --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sqy8qDr98Njm"
   },
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    net, \n",
    "    data_module\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IeB7jzb8Njn"
   },
   "outputs": [],
   "source": [
    "best = ContextualRanker.load_from_checkpoint(checkpoint_callback.best_model_path, embedding_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTUgc8_hQ7N0"
   },
   "outputs": [],
   "source": [
    "trainer.test(best, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRZLUR9_8Njo"
   },
   "source": [
    "## Compute top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UrLSjgt8Njo"
   },
   "outputs": [],
   "source": [
    "track_meta = pd.read_json(DATA_DIR + \"tracks.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqwVsVyO8Njp"
   },
   "outputs": [],
   "source": [
    "context_embeddings = dict(best.named_parameters())[\"context.weight\"].data.cpu().numpy()\n",
    "track_embeddings = dict(best.named_parameters())[\"track.weight\"].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-z1VTPGh8Njp"
   },
   "outputs": [],
   "source": [
    "track_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7_A20no8Njp"
   },
   "outputs": [],
   "source": [
    "k = 100\n",
    "with open(DATA_DIR + \"tracks_with_recs.json\", \"w\") as rf:\n",
    "    for _, track in tqdm.tqdm(track_meta.iterrows()):\n",
    "        embedding = context_embeddings[track[\"track\"]]\n",
    "        neighbours = np.argpartition(-np.dot(track_embeddings, embedding), k)[:k]\n",
    "        \n",
    "        recommendation = dict(track)\n",
    "        recommendation[\"recommendations\"] = neighbours.tolist()\n",
    "        \n",
    "        rf.write(json.dumps(recommendation) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhS_o_ff8Njp"
   },
   "outputs": [],
   "source": [
    "track = 3916\n",
    "embedding = context_embeddings[track]\n",
    "track_meta.loc[track_meta[\"track\"] == track, [\"artist\", \"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGFHEN8g8Njq"
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "neighbours = np.argpartition(-np.dot(track_embeddings, embedding), k)[:k]\n",
    "track_meta.loc[track_meta[\"track\"].isin(neighbours), [\"artist\", \"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymCblQht8Njq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
