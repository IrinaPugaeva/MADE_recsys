@article{DDPG,
  title={Deep Reinforcement Learning in Large Discrete Action Spaces},
  author={Gabriel Dulac-Arnold and Richard Evans and H. V. Hasselt and Peter Sunehag and Timothy P. Lillicrap and Jonathan J. Hunt and Timothy A. Mann and Th{\'e}ophane Weber and Thomas Degris and Ben Coppin},
  journal={arXiv: Artificial Intelligence},
  year={2015}
}

@misc{RECSIM,
  abstract = {We propose RecSim, a configurable platform for authoring simulation
environments for recommender systems (RSs) that naturally supports sequential
interaction with users. RecSim allows the creation of new environments that
reflect particular aspects of user behavior and item structure at a level of
abstraction well-suited to pushing the limits of current reinforcement learning
(RL) and RS techniques in sequential interactive recommendation problems.
Environments can be easily configured that vary assumptions about: user
preferences and item familiarity; user latent state and its dynamics; and
choice models and other user response behavior. We outline how RecSim offers
value to RL and RS researchers and practitioners, and how it can serve as a
vehicle for academic-industrial collaboration.},
  added-at = {2019-10-18T11:27:26.000+0200},
  author = {Ie, Eugene and Hsu, Chih-wei and Mladenov, Martin and Jain, Vihan and Narvekar, Sanmit and Wang, Jing and Wu, Rui and Boutilier, Craig},
  biburl = {https://www.bibsonomy.org/bibtex/21401d7bcb9f90b441b7124f7f4ce8fa0/e.fischer},
  description = {[1909.04847] RecSim: A Configurable Simulation Platform for Recommender Systems},
  interhash = {c50609d4ae33c77cb57e4b788b2562ba},
  intrahash = {1401d7bcb9f90b441b7124f7f4ce8fa0},
  keywords = {recommendation simulation},
  note = {cite arxiv:1909.04847},
  timestamp = {2019-10-18T11:27:26.000+0200},
  title = {RecSim: A Configurable Simulation Platform for Recommender Systems},
  url = {http://arxiv.org/abs/1909.04847},
  year = 2019
}

@misc{BANDITS1, title={Multi-Armed Bandits and Reinforcement Learning}, url={https://towardsdatascience.com/multi-armed-bandits-and-reinforcement-learning-dc9001dcb8da}, journal={towardsdatascience.com}, year={2019}}

@misc{BANDITS2, title={Multi-Armed Bandits and Reinforcement Learning 2}, url={https://www.datahubbs.com/multi-armed-bandits-reinforcement-learning-2/}, journal={datahubbs.com}, year={2019}}

@misc{BANDITS3, title={13 Solutions to Multi-Arm Bandit Problem for Non-Mathematicians}, url={https://towardsdatascience.com/13-solutions-to-multi-arm-bandit-problem-for-non-mathematicians-1b88b4c0b3fc}, journal={towardsdatascience.com}, year={2019}}

@article{TOPK,
  author    = {Minmin Chen and
               Alex Beutel and
               Paul Covington and
               Sagar Jain and
               Francois Belletti and
               Ed H. Chi},
  title     = {Top-K Off-Policy Correction for a {REINFORCE} Recommender System},
  journal   = {CoRR},
  volume    = {abs/1812.02353},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.02353},
  eprinttype = {arXiv},
  eprint    = {1812.02353},
  timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-02353.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

